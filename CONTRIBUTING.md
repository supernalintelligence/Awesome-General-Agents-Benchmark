# Contributing to Awesome AI Agent Benchmarks

Thank you for your interest in contributing to the Awesome AI Agent Benchmarks project! This document provides guidelines and instructions for contributing.

## How to Contribute

There are several ways you can contribute to this project:

1. **Adding new benchmarks**: If you know of a benchmark that's not listed, you can add it.
2. **Updating existing benchmarks**: Keep information current by updating benchmark details, top performers, etc.
3. **Improving documentation**: Enhance explanations, fix typos, or clarify content.
4. **Reporting issues**: Report any inaccuracies, broken links, or other problems.

## Contribution Process

### For Small Changes (Typos, Link Fixes)

1. Fork the repository
2. Make your changes
3. Submit a pull request with a clear description of the changes

### For New Benchmarks or Major Updates

1. Fork the repository
2. Create a new branch for your changes
3. Add your new benchmark(s) or make your updates
4. Submit a pull request with detailed information

## Benchmark Inclusion Criteria

To be included in this list, benchmarks should:

1. **Be relevant**: Specifically test AI agent or frontier model capabilities
2. **Be rigorous**: Have a clearly defined evaluation methodology and metrics
3. **Be reproducible**: Results should be independently verifiable
4. **Have impact**: Be recognized or adopted by the research community
5. **Be recent**: Focus on benchmarks that represent current state-of-the-art challenges
6. **Add diversity**: Ideally cover capabilities or domains not already well-represented

## Format for Adding Benchmarks

When adding a new benchmark, please follow this format:

```markdown
| [Benchmark Name](link-to-benchmark) | Brief description of focus | Top model (score%), Runner-up (score%) | Human baseline |
```

For example:

```markdown
| [MMLU](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) | 57-domain knowledge across academic subjects | GPT-4.1 (90.2%), Gemini 2.5 Pro (89.0%) | 89% |
```

## Pull Request Review Process

1. A maintainer will review your PR
2. They may request changes or clarification
3. Once approved, your contribution will be merged

## Code of Conduct

This project follows the [Contributor Covenant](https://www.contributor-covenant.org/version/2/1/code_of_conduct/) Code of Conduct. By participating, you are expected to uphold this code.

## Questions?

If you have any questions about contributing, please email [i@supernal.ai](mailto:i@supernal.ai) or open an issue.

Thank you for helping improve Awesome AI Agent Benchmarks! 